---
title: 1.12.0 版本发布
author: Mingyu Bao
author_url: https://github.com/baomingyu
author_image_url: https://avatars.githubusercontent.com/u/8108604?s=400&v=4
tags: [Apache InLong, Version]
---

Apache InLong（应龙）最近发布了 1.12.0 版本，该版本关闭了 140+ 个 Issues ，包含 7+ 个大特性和 90+ 个优化，主要完成了 Manager 对 Agent 安装包的管理和自升级流程的管理、Agent 支持自升级流程、Agent 对 Kafka/Pulsar/MongoDB 采集的支持、Audit 方案优化及能力增强、Sort 新增支持 Redis Connector 等特性。1.12.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景， 增强了 Audit 数据度量的准确性，丰富了 Sort 的能力和适用场景，同时优化了 Apache InLong 运营、运维过程中遇到的一些问题和使用体验。
<!--truncate-->

## 关于 Apache InLong
作为业界首个一站式、全场景海量数据集成框架，Apache InLong（应龙）提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。

InLong 项目定位的核心关键词是“一站式”、“全场景”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“全场景”，我们希望提供全方位的解决方案，覆盖大数据领域常见的数据集成场景；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。

## 1.12.0 版本总览
Apache InLong（应龙）最近发布了 1.12.0 版本，该版本关闭了 140+ 个 Issues ，包含 7+ 个大特性和 90+ 个优化，主要完成了 Manager 对 Agent 安装包的管理和自升级流程的管理、Agent 支持自升级流程、Agent 对 Kafka/Pulsar/MongoDB 采集的支持、Audit 方案优化及能力增强、Sort 新增支持 Redis Connector 等特性。1.12.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景，增强了 Audit 数据度量的准确性，丰富了 Sort 的能力和适用场景，同时优化了 Apache InLong 运营、运维过程中遇到的一些问题和使用体验。Apache InLong 1.12.0 版本中，还完成了大量其它特性，主要包括：

### Agent 模块
- 支持 Agent 自升级版本
- 优化初始化逻辑降低 IO 使用率
- 优化消息确认逻辑，减少信号量竞争
- 增加异常和重发审计数据
- 优化了补数据流程，避免因补文件过多导致丢数据

### Manager 模块
- 支持 Agent、Installer 安装包管理以及自升级流程管理
- 支持在数据预览时根据 CSV 等数据类型解析具体字段信息
- 数据预览支持多集群条件下查询数据
- 数据预览支持获取消息头等额外信息
- 支持配置文件采集补录任务
- 审计数据查询从直接与数据库交互切换至 Audit OpenAPI
- Pulsar Sink 支持配置 Pulsar SDK 消费时所需压缩格式
- 提供批量保存 InLongGroup、InLongStream 等信息的 OpenAPI
- 支持 Kafka Datanode 管理

### Dashboard 模块
- 审计数据查询优化
- 审计数据展示优化
- Sink 字段映射支持下划线“_”
- 资源详情展示支持分页
- 支持 MongoDB 数据源配置

### Audit 模块
- 支持用户自定义方式获取 Audit proxy 信息
- Audit SDK 支持上报版本号
- Audit SDK 支持单例、非单例两种使用方式
- Audit SDK 支持 Flink Checkpoint 特性下的数据上报方式
- Audit Service 支持 HA 能力
- Audit Service 支持本地缓存及 OpenApi
- Audit Service 支持多数据源集群

### Sort 模块
- StarRocks Connector 在初始化时支持使用 state key
- 支持解析含有分割服的 KV、CSV 数据
- 使用 ZLIB 作为 Pulsar Sink 的默认压缩类型
- Pulsar Connector 支持认证配置
- Pulsar Sink 支持认证配置
- Redis Source 支持 String、Hash、ZSet 数据类型的读取
- Redis Sink 支持 Bitmap、Hash、String 数据类型

## 1.12.0 版本特性介绍

### Manager 支持对 Agent 安装管理
通过此特性，运维人员可以通过 Dashboard 管理 Agent 的发布包，包括 Agent 安装、升级、心跳管理等。用户在系统运维 ->> 安装包 ->> Agent 页面创建/管理安装包。感谢 @haifxu、@fuweng11 两位同学在 Dashboard 及 Manager 部分对此功能的贡献。具体可参考：INLONG-9932。
![1.12.0-agent-package.png](img%2F1.12.0-agent-package.png)

### Agent 支持自升级
Agent 可以通过提前部署的 Installer 完成自升级操作，Installer 会通过 IP 从 InLong manager 获取升级的配置信息，根据配置判断是否升级主要流程：
- 新增流程：下载安装包 -> 解压安装包 -> 启动进程
- 删除流程：停止进程 -> 删除安装文件
- 更新流程：下载安装包 -> 停止进程 -> 删除安装文件 -> 解压安装包 -> 启动进程
感谢 @justinwwhuang  对此功能的贡献，具体可参考 INLONG-9801 。
![1.12.0-agent-upgrade.png](img%2F1.12.0-agent-upgrade.png)

### Agent 支持 Kafka 采集
在 1.12.0 版本中，Agent 支持了从 Kafka 采集数据，在数据源创建时可以直接选择 Kafka，填写相关数据源信息即可开始使用，参数包括：
- 数据源名称：便于快速区分不同的数据源
- 集群名称：选择该数据源所属的集群
- 数据源 IP：选择该数据源所属的机器
- Bootstrap Servers：Kafka 集群地址
- Topic：改数据源要订阅的 Kafka Topic
- 自动偏移重置：设置偏移策略
- 分区位点：可精确指定具体分区位点
感谢 @haifxu 对此功能的贡献，具体请参考 INLONG-9741 。
![1.12.0-agent-kafka.png](img%2F1.12.0-agent-kafka.png)

### Agent 支持 Pulsar 采集
在 1.12.0 版本中，Agent 支持了从 Pulsar 采集数据，在数据源创建时可以直接选择 Pulsar，填写相关数据源信息即可开始使用，参数包括：
- 数据源名称：便于快速区分不同的数据源
- 集群名称：选择该数据源所属的集群
- 数据源 IP：选择该数据源所属的机器
- Pulsar 租户：Pulsar 租户
- 命名空间：Pulsar 命名空间
- Pulsar topic：数据源要订阅的 topic
- Admin url：Pulsar admin url
- Service url：Pulsar service url
感谢 @justinwwhuang 同学对此功能的贡献，具体可参考 INLONG-9804
![1.12.0-agent-pulsar.png](img%2F1.12.0-agent-pulsar.png)

### Agent 支持 MongoDB 采集
在 1.12.0 版本中，Agent 支持了从 MongoDB 采集数据，在数据源创建时可以直接选择 MongoDB，填写相关数据源信息即可开始使用，参数包括：
- 数据源名称：便于快速区分不同的数据源
- 集群名称：选择该数据源所属的集群
- 数据源 IP：选择该数据源所属的机器
- 服务器主机：MongoDB 地址
- 用户名：MongoDB 用户名
- 密码：MongoDB 密码
- 数据库名：MongoDB 数据库名
- 集合名称：MongoDB 集合名称
- 读取模式：可选“全量 + 增量” 或 “增量”
感谢 @justinwwhuang 同学对此功能的贡献，具体可参考 INLONG-10006。
![1.12.0-agent-mongodb.png](img%2F1.12.0-agent-mongodb.png)

### Audit 支持多场景对账
在 1.12.0 版本中，InLong 丰富了 Audit 审计对账的场景，包括支持 Agent 数据补录场景、Sort on Flink Checkpoint 场景等，特别感谢 @doleyzi 同学对此功能的贡献，具体可参考 INLONG-9904、INLONG-9926、INLONG-9928、INLONG-9957 等。
- 新增 OpenAPI 能力
在 1.12.0 版本，Audit 新增了 OpenAPI 的能力，各个 OpenAPI 可以通过 HA 进行选主，Leader 节点负责对审计数据源进行实时、回溯聚合，并且将聚合结果保存在 DB 中，Slave 节点负责将 DB 的数据 cache 到内存，对外提供服务( Leader 节点同样也提供该服务)
![1.12.0-audit-process.png](img%2F1.12.0-audit-process.png)
- 新增 Agent 数据补录的能力
在 1.12.0 版本，审计支持了 Agent 数据补录的场景，通过新增 audit-version，区分每次补录的审计对账
![1.12.0-audit-recovery.png](img%2F1.12.0-audit-recovery.png)
- 支持 Sort Flink Checkpoint 能力
在 1.12.0 版本，审计支持了 Sort Flink 的 checkpoint 的场景，在 Flink 作业重启或者 failover 时，能够保证审计数据不丢不重，从而保证全流程的审计对账
![1.12.0-audit-checkpoint.png](img%2F1.12.0-audit-checkpoint.png)

### Sort 新增 Redis Connector
在 1.12.0 版本，增加了基于 Flink 1.15 支持的 Redis connector 实现，支持对 Redis 集群和单机的 String、Hash、ZSet、Bitmap 四种常用数据类型读取和写入，在 Redis connector 内部实现了 Schema 转换，可以将用户指定的 Schema 转换为不同的 Redis Data Type。具体 Schema 转换逻辑如下图所示，在下图的 Bitmap 转换逻辑中，field1 作为 Bitmap 的 key， filed2、field4 作为 Bitmap 中的位置(index), filed3、field5 为设置的值(0 或 1)。具体可参考 Redis 原生命令 SETBIT key index value。感谢 @XiaoYou201 同学对此功能的贡献，具体可参考 INLONG-9835、INLONG-8948 。
![1.12.0-redis-connector.png](img%2F1.12.0-redis-connector.png)

## 未来规划
在 1.12.0 版本中，社区重构了 InLong Agent，InLong Audit，丰富了 Flink 1.15 Connector 等功能。在后续的版本中，InLong 将继续丰富 Flink 1.15 Connector 、丰富 Transform 能力、支持离线集成、统一 DataProxy 数据协议、Dashboard 体验优化等，期待更多开发者参与贡献。
